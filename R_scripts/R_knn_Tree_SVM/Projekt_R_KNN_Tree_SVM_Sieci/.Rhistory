print(paste("Najlepszy NN w R - Regresja: h = ", NN_reg_R[["finalModel"]][["tuneValue"]][["size"]], " | MAE = " , NN_reg_R_Wynik$MAE[NN_reg_R_Wynik$size == NN_reg_R[["finalModel"]][["tuneValue"]][["size"]]]))
ggplot(NN_reg_R_Wynik , aes(x=size)) +
geom_line(aes(y = MAE), size=1, color="blue") +
labs(title='Blad w zaleznosci od liczby neuronow - regresja (CARET)', x='h', y='MAE')
print("Neural Network - R")
nn_grid_bin = expand.grid(size=4:10, decay=0)
NN_bin_R = train(x=df_bin_norm[,X_nazwy_bin], y=as.factor(df_bin_norm[,Y_nazwy_bin]), tuneGrid=nn_grid_bin, method='nnet', metric='Accuracy', trControl=cv_R)
NN_bin_R_Wynik = NN_bin_R$results
print(paste("Najlepszy NN w R - Binarny: h = ", NN_bin_R[["finalModel"]][["tuneValue"]][["size"]], " | Accuracy = " , NN_bin_R_Wynik$Accuracy[NN_bin_R_Wynik$size == NN_bin_R[["finalModel"]][["tuneValue"]][["size"]]]))
ggplot(NN_bin_R_Wynik , aes(x=size)) +
geom_line(aes(y = Accuracy), size=1, color="blue") +
labs(title='NNET: Accuracy w zaleznosci od liczby neuronow - Wieloklasowy', x='h', y='Accuracy')
nn_grid_multi = expand.grid(size=4:10, decay=0)
NN_multi_R = train(x=df_multi_norm[,X_nazwy_multi], y=as.factor(df_multi_norm[,Y_nazwy_multi]), tuneGrid=nn_grid_multi, method='nnet', metric='Accuracy', trControl=cv_R)
NN_multi_R_Wynik = NN_multi_R$results
print(paste("Najlepszy NN w R - Wieloklasowy: h = ", NN_multi_R[["finalModel"]][["tuneValue"]][["size"]], " | Accuracy = " , NN_multi_R_Wynik$Accuracy[NN_multi_R_Wynik$size == NN_multi_R[["finalModel"]][["tuneValue"]][["size"]]]))
ggplot(NN_multi_R_Wynik , aes(x=size)) +
geom_line(aes(y = Accuracy), size=1, color="blue") +
labs(title='NNET: Accuracy w zaleznosci od liczby neuronow - Wieloklasowy', x='h', y='Accuracy')
nn_grid_reg = expand.grid(size=4:10, decay = 0.00001)
NN_reg_R = train(x=df_reg_norm[,X_nazwy_reg], y=(df_reg[,Y_nazwy_reg]), tuneGrid=nn_grid_reg, method='nnet', metric='MAE', trControl=cv_R)
NN_reg_R_Wynik = NN_reg_R$results
print(paste("Najlepszy NN w R - Regresja: h = ", NN_reg_R[["finalModel"]][["tuneValue"]][["size"]], " | MAE = " , NN_reg_R_Wynik$MAE[NN_reg_R_Wynik$size == NN_reg_R[["finalModel"]][["tuneValue"]][["size"]]]))
ggplot(NN_reg_R_Wynik , aes(x=size)) +
geom_line(aes(y = MAE), size=1, color="blue") +
labs(title='NNET: MAE w zaleznosci od liczby neuronow - Regresja', x='h', y='MAE')
ggplot(NN_bin_R_Wynik , aes(x=size)) +
geom_line(aes(y = Accuracy), size=1, color="blue") +
labs(title='NNET: Accuracy w zaleznosci od liczby neuronow - Binarny', x='h', y='Accuracy')
nn_grid_bin = expand.grid(size=4:10, decay=0.00001)
NN_bin_R = train(x=df_bin_norm[,X_nazwy_bin], y=as.factor(df_bin_norm[,Y_nazwy_bin]), tuneGrid=nn_grid_bin, method='nnet', metric='Accuracy', trControl=cv_R)
NN_bin_R_Wynik = NN_bin_R$results
print(paste("Najlepszy NN w R - Binarny: h = ", NN_bin_R[["finalModel"]][["tuneValue"]][["size"]], " | Accuracy = " , NN_bin_R_Wynik$Accuracy[NN_bin_R_Wynik$size == NN_bin_R[["finalModel"]][["tuneValue"]][["size"]]]))
ggplot(NN_bin_R_Wynik , aes(x=size)) +
geom_line(aes(y = Accuracy), size=1, color="blue") +
labs(title='NNET: Accuracy w zaleznosci od liczby neuronow - Binarny', x='h', y='Accuracy')
nn_grid_multi = expand.grid(size=4:10, decay=0.00001)
NN_multi_R = train(x=df_multi_norm[,X_nazwy_multi], y=as.factor(df_multi_norm[,Y_nazwy_multi]), tuneGrid=nn_grid_multi, method='nnet', metric='Accuracy', trControl=cv_R)
NN_multi_R_Wynik = NN_multi_R$results
print(paste("Najlepszy NN w R - Wieloklasowy: h = ", NN_multi_R[["finalModel"]][["tuneValue"]][["size"]], " | Accuracy = " , NN_multi_R_Wynik$Accuracy[NN_multi_R_Wynik$size == NN_multi_R[["finalModel"]][["tuneValue"]][["size"]]]))
ggplot(NN_multi_R_Wynik , aes(x=size)) +
geom_line(aes(y = Accuracy), size=1, color="blue") +
labs(title='NNET: Accuracy w zaleznosci od liczby neuronow - Wieloklasowy', x='h', y='Accuracy')
nn_grid_reg = expand.grid(size=4:10, decay = 0.00001)
NN_reg_R = train(x=df_reg_norm[,X_nazwy_reg], y=(df_reg[,Y_nazwy_reg]), tuneGrid=nn_grid_reg, method='nnet', metric='MAE', trControl=cv_R)
NN_reg_R_Wynik = NN_reg_R$results
print(paste("Najlepszy NN w R - Regresja: h = ", NN_reg_R[["finalModel"]][["tuneValue"]][["size"]], " | MAE = " , NN_reg_R_Wynik$MAE[NN_reg_R_Wynik$size == NN_reg_R[["finalModel"]][["tuneValue"]][["size"]]]))
ggplot(NN_reg_R_Wynik , aes(x=size)) +
geom_line(aes(y = MAE), size=1, color="blue") +
labs(title='NNET: MAE w zaleznosci od liczby neuronow - Regresja', x='h', y='MAE')
ggplot(Tree_bin_R_Wynik , aes(x=maxdepth)) +
geom_line(aes(y = Accuracy), size=1, color='blue') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='Max Depth', y='Accuracy')+
theme(legend.position = "bottom")
ggplot(Tree_multi_R_Wynik , aes(x=maxdepth)) +
geom_line(aes(y = Accuracy), size=1, color='blue') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='Max Depth', y='Accuracy')+
theme(legend.position = "bottom")
ggplot(Tree_reg_R_Wynik , aes(x=maxdepth)) +
geom_line(aes(y = MAE), size=1, color='blue') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='Max Depth', y='MAE')+
theme(legend.position = "bottom")
View(NN_CV_reg_cbind)
View(NN_CV_reg)
View(NN_CV_reg)
View(NN_CV_reg)
ggplot(NN_CV_reg , aes(x=h[1])) +
geom_line(aes(y = MAE_TRAIN), size=1, color='blue') +
geom_line(aes(y = MAE_TEST), size=1, color='red')
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='Max Depth', y='Accuracy')+
theme(legend.position = "bottom")
### Funkcje wbudowane w biblioteki R ###
cat("\n")
View(KNN_CV_bin)
View(KNN_CV_bin)
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_Train), size=1, color='blue') +
geom_line(aes(y = Jakosc_Test), size=1, color='red') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='Max Depth', y='Accuracy')+
theme(legend.position = "bottom")
View(KNN_CV_bin)
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN), size=1, color='blue') +
geom_line(aes(y = Jakosc_TEST), size=1, color='red') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='Max Depth', y='Accuracy')+
theme(legend.position = "bottom")
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN), size=1, color='blue', label) +
geom_line(aes(y = Jakosc_TEST), size=1, color='red') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='k', y='Accuracy') +
scale_color_discrete(name = "Accuracy", labels = c("Train", "Test")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN), size=1, color='blue') +
geom_line(aes(y = Jakosc_TEST), size=1, color='red') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='k', y='Accuracy') +
scale_color_discrete(name = "Accuracy", labels = c("Train", "Test")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN), size=1, color='blue') +
geom_line(aes(y = Jakosc_TEST), size=1, color='red') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='k', y='Accuracy') +
scale_color_discrete(name = "Accuracy", labels = c("Train", "Test")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN), size=1, color='blue') +
geom_line(aes(y = Jakosc_TEST), size=1, color='red') +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Accuracy", labels = c("Train", "Test")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN), size=1, color='blue') +
geom_line(aes(y = Jakosc_TEST), size=1, color='red') +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy', labels = c("Train", "Test")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
theme(legend.position = "bottom")
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Y series", labels = c("Y2", "Y1")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
theme(legend.position = "bottom")
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
View(KNN_CV_bin)
ggplot(KNN_CV_multi , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_reg , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
View(KNN_reg_R)
View(KNN_CV_reg)
ggplot(KNN_CV_reg , aes(x=k)) +
geom_line(aes(y = MAE_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = MAE_TEST, color='red'), size=1,) +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(SVM_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='SVM: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(SVM_CV_bin , aes(x=C)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='SVM: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(SVM_CV_bin[1:50] , aes(x=C)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='SVM: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(SVM_CV_bin[1:50,] , aes(x=C)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='SVM: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(SVM_CV_bin[1:100,] , aes(x=C)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='SVM: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(NN_CV_bin , aes(x=h[1])) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(NN_CV_bin , aes(x=h)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Jakosc od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
print(NN_CV_bin)
print(NN_CV_multi)
print(NN_CV_reg)
#binarna
Drzewko_bin <- Tree(Y_nazwy_bin, X_nazwy_bin, data=df_bin, type='Gini', depth=Tree_bin_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
plot(Drzewko_bin)
#wieloklasowa
Drzewko_multi <- Tree(Y_nazwy_multi, X_nazwy_multi, data=df_multi, type='Gini', depth=Tree_multi_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
plot(Drzewko_multi)
#regresja -
Drzewko_reg <- Tree(Y_nazwy_reg, X_nazwy_reg, data=df_reg, type='SS', depth=Tree_reg_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
plot(Drzewko_reg)
plot(Drzewko_bin, output = visNetwork)
plot(Drzewko_bin, output = "visNetwork")
print(Drzewko_bin)
print(Drzewko_multi)
print(Drzewko_reg)
#Binarna
print("Wlasna Implementacja - Drzewa Decyzyjne - Diagramy")
cat("\n")
print("Drzewa Decyzyjne - Binarny")
Drzewko_bin <- Tree(Y_nazwy_bin, X_nazwy_bin, data=df_bin, type='Gini', depth=Tree_bin_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
plot(Drzewko_bin)
print(Drzewko_bin)
#Wieloklasowa
print("Drzewa Decyzyjne - Wieloklasowy")
Drzewko_multi <- Tree(Y_nazwy_multi, X_nazwy_multi, data=df_multi, type='Gini', depth=Tree_multi_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
plot(Drzewko_multi)
print(Drzewko_multi)
#Regresja
print("Drzewa Decyzyjne - Regresja")
Drzewko_reg <- Tree(Y_nazwy_reg, X_nazwy_reg, data=df_reg, type='SS', depth=Tree_reg_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
plot(Drzewko_reg)
print(Drzewko_reg)
print(KNN_CV_bin[which.max(KNN_CV_bin$Jakosc_TRAIN),])
print(KNN_CV_bin[which.max(KNN_CV_bin$Jakosc_TEST),])
print(KNN_CV_multi[which.max(KNN_CV_multi$Jakosc_TRAIN),])
print(KNN_CV_multi[which.max(KNN_CV_multi$Jakosc_TEST),])
print(KNN_CV_reg[which.min(KNN_CV_reg$MAPE_TRAIN),])
print(KNN_CV_reg[which.min(KNN_CV_reg$MAPE_TEST),])
print(SVM_CV_bin[which.max(SVM_CV_bin$Jakosc_TRAIN),])
print(SVM_CV_bin[which.max(SVM_CV_bin$Jakosc_TEST),])
print(NN_CV_bin[which.max(NN_CV_bin$Jakosc_TRAIN),])
print(NN_CV_bin[which.max(NN_CV_bin$Jakosc_TEST),])
save.image("D:/Programming/Python_Micro_Codes/R_knn_Tree_SVM/Projekt_R_KNN_Tree_SVM_Sieci/Kappa_2_w_nocy.RData")
print(NN_CV_multi[which.max(NN_CV_multi$Jakosc_TRAIN),])
print(NN_CV_multi[which.max(NN_CV_multi$Jakosc_TEST),])
print(NN_CV_reg[which.min(NN_CV_reg$MAPE_TRAIN),])
print(NN_CV_reg[which.min(NN_CV_reg$MAPE_TEST),])
print(paste("Najlepszy KNN w R - Binarny: k = ", KNN_bin_R$finalModel$k, " | Accuracy = " ,KNN_bin_R_Wynik$Accuracy[KNN_bin_R_Wynik$k == KNN_bin_R$finalModel$k]))
print(paste("Najlepszy KNN w R - Wieloklasowy: k = ", KNN_multi_R$finalModel$k, " | Accuracy = " ,KNN_multi_R_Wynik$Accuracy[KNN_multi_R_Wynik$k == KNN_multi_R$finalModel$k]))
print(paste("Najlepszy KNN w R - Regresja: k = ", KNN_reg_R$finalModel$k, " | MAE = " ,KNN_reg_R_Wynik$MAE[KNN_reg_R_Wynik$k == KNN_reg_R$finalModel$k]))
print(paste("Najlepszy SVM w R - Binarny: Cost = ", SVM_bin_R[["finalModel"]]@param[["C"]], " | Accuracy = " , SVM_bin_R_Wynik$Accuracy[SVM_bin_R_Wynik$C == SVM_bin_R[["finalModel"]]@param[["C"]]]))
print(paste("Najlepszy NN w R - Binarny: h = ", NN_bin_R[["finalModel"]][["tuneValue"]][["size"]], " | Accuracy = " , NN_bin_R_Wynik$Accuracy[NN_bin_R_Wynik$size == NN_bin_R[["finalModel"]][["tuneValue"]][["size"]]]))
print(paste("Najlepszy NN w R - Wieloklasowy: h = ", NN_multi_R[["finalModel"]][["tuneValue"]][["size"]], " | Accuracy = " , NN_multi_R_Wynik$Accuracy[NN_multi_R_Wynik$size == NN_multi_R[["finalModel"]][["tuneValue"]][["size"]]]))
print(paste("Najlepszy NN w R - Regresja: h = ", NN_reg_R[["finalModel"]][["tuneValue"]][["size"]], " | MAE = " , NN_reg_R_Wynik$MAE[NN_reg_R_Wynik$size == NN_reg_R[["finalModel"]][["tuneValue"]][["size"]]]))
print(paste("Najlepszy NN w R - Regresja: h = ", NN_reg_R[["finalModel"]][["tuneValue"]][["size"]], " | MAE = " , NN_reg_R_Wynik$MAE[NN_reg_R_Wynik$size == NN_reg_R[["finalModel"]][["tuneValue"]][["size"]]]))
print(paste("Najlepszy Tree w R - Binarny: Max Depth = ", Tree_bin_R[["finalModel"]][["tuneValue"]][["maxdepth"]], " | Accuracy = " , Tree_bin_R_Wynik$Accuracy[Tree_bin_R_Wynik$maxdepth == Tree_bin_R[["finalModel"]][["tuneValue"]][["maxdepth"]]]))
print(paste("Najlepszy Tree w R - Wieloklasowy: Max Depth = ", Tree_multi_R[["finalModel"]][["tuneValue"]][["maxdepth"]], " | Accuracy = " , Tree_multi_R_Wynik$Accuracy[Tree_multi_R_Wynik$maxdepth == Tree_multi_R[["finalModel"]][["tuneValue"]][["maxdepth"]]]))
ggplot(Tree_reg_R_Wynik , aes(x=maxdepth)) +
geom_line(aes(y = MAE), size=1, color='blue') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia', x='Max Depth', y='MAE')+
theme(legend.position = "bottom")
print(paste("Najlepszy Tree w R - Regresja: Max Depth = ", Tree_reg_R[["finalModel"]][["tuneValue"]][["maxdepth"]], " | MAE = " , Tree_reg_R_Wynik$MAE[Tree_reg_R_Wynik$maxdepth == Tree_reg_R[["finalModel"]][["tuneValue"]][["maxdepth"]]]))
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Accuracy od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_multi , aes(x=k)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='KNN: Accuracy od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_reg , aes(x=k)) +
geom_line(aes(y = MAE_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = MAE_TEST, color='red'), size=1,) +
labs(title='KNN: MAE od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_reg , aes(x=k)) +
geom_line(aes(y = MAE_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = MAE_TEST, color='red'), size=1,) +
labs(title='KNN: MAE od k', x='k', y='MAE') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
ggplot(KNN_CV_reg , aes(x=k)) +
geom_line(aes(y = MAPE_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = MAPE_TEST, color='red'), size=1,) +
labs(title='KNN: MAE od k', x='k', y='MAE') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
View(NN_bin_R_Wynik)
View(KNN_bin_R)
View(KNN_bin_R_Wynik)
Porownanie_KNN_Bin <- cbind(KNN_CV_bin$k[1:40], KNN_CV_bin$Jakosc_TEST[1:40], KNN_bin_R_Wynik$Accuracy[1:40])
View(Porownanie_KNN_Bin)
Porownanie_KNN_Bin <- cbind(k = KNN_CV_bin$k[1:40], KNN_w = KNN_CV_bin$Jakosc_TEST[1:40], KNN_R = KNN_bin_R_Wynik$Accuracy[1:40])
View(Porownanie_KNN_Bin)
Porownanie_KNN_Bin <- cbind(k = KNN_CV_bin$k[1:40], KNN_W = KNN_CV_bin$Jakosc_TEST[1:40], KNN_R = KNN_bin_R_Wynik$Accuracy[1:40])
Porownanie_KNN_Bin <- cbind(k = KNN_CV_bin$k[1:40], KNN_W = KNN_CV_bin$Jakosc_TEST[1:40], KNN_R = KNN_bin_R_Wynik$Accuracy[1:40])
ggplot(KNN_CV_bin , aes(x=k)) +
geom_line(aes(y = KNN_W, color='blue'), size=1, ) +
geom_line(aes(y = KNN_R, color='red'), size=1,) +
labs(title='KNN: Accuracy od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
ggplot(Porownanie_KNN_Bin , aes(x=k)) +
geom_line(aes(y = KNN_W, color='blue'), size=1, ) +
geom_line(aes(y = KNN_R, color='red'), size=1,) +
labs(title='KNN: Accuracy od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
Porownanie_KNN_Bin <- data.frame(cbind(k = KNN_CV_bin$k[1:40], KNN_W = KNN_CV_bin$Jakosc_TEST[1:40], KNN_R = KNN_bin_R_Wynik$Accuracy[1:40]))
ggplot(Porownanie_KNN_Bin , aes(x=k)) +
geom_line(aes(y = KNN_W, color='blue'), size=1, ) +
geom_line(aes(y = KNN_R, color='red'), size=1,) +
labs(title='KNN: Accuracy od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
Porownanie_KNN_Multi <- data.frame(cbind(k = KNN_CV_multi$k[1:40], KNN_W = KNN_CV_multi$Jakosc_TEST[1:40], KNN_R = KNN_multi_R_Wynik$Accuracy[1:40]))
ggplot(Porownanie_KNN_Multi , aes(x=k)) +
geom_line(aes(y = KNN_W, color='blue'), size=1, ) +
geom_line(aes(y = KNN_R, color='red'), size=1,) +
labs(title='KNN: Accuracy od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
Porownanie_KNN_Reg <- data.frame(cbind(k = KNN_CV_reg$k[1:40], KNN_W = KNN_CV_reg$Jakosc_TEST[1:40], KNN_R = KNN_reg_R_Wynik$Accuracy[1:40]))
ggplot(Porownanie_KNN_Reg , aes(x=k)) +
geom_line(aes(y = KNN_W, color='blue'), size=1, ) +
geom_line(aes(y = KNN_R, color='red'), size=1,) +
labs(title='KNN: Accuracy od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
Porownanie_KNN_Reg <- data.frame(cbind(k = KNN_CV_reg$k[1:40], KNN_W = KNN_CV_reg$Jakosc_TEST[1:40], KNN_R = KNN_reg_R_Wynik$Accuracy[1:40]))
Porownanie_KNN_Reg <- data.frame(cbind(k = KNN_CV_reg$k[1:40], KNN_W = KNN_CV_reg$MAE_TEST[1:40], KNN_R = KNN_reg_R_Wynik$MAE[1:40]))
ggplot(Porownanie_KNN_Reg , aes(x=k)) +
geom_line(aes(y = KNN_W, color='blue'), size=1, ) +
geom_line(aes(y = KNN_R, color='red'), size=1,) +
labs(title='KNN: Accuracy od k', x='k', y='Accuracy') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
ggplot(Porownanie_KNN_Reg , aes(x=k)) +
geom_line(aes(y = KNN_W, color='blue'), size=1, ) +
geom_line(aes(y = KNN_R, color='red'), size=1,) +
labs(title='KNN: MAE od k', x='k', y='MAE') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
ggplot(SVM_CV_bin[1:100,] , aes(x=C)) +
geom_line(aes(y = Jakosc_TRAIN, color='blue'), size=1, ) +
geom_line(aes(y = Jakosc_TEST, color='red'), size=1,) +
labs(title='SVM: Jakosc od C (kosztu)', x='C', y='Accuracy') +
scale_color_discrete(name = "Zbiór", labels = c("Treningowy", "Testowy")) +
theme(legend.position = "bottom")
Porownanie_SVM_Bin <- data.frame(cbind(C = SVM_CV_bin$C[1:100], SVM_W = SVM_CV_bin$Jakosc_TEST[1:100], SVM_R = SVM_bin_R_Wynik$Accuracy[1:100]))
ggplot(Porownanie_KNN_Reg , aes(x=k)) +
geom_line(aes(y = KNN_W, color='blue'), size=1, ) +
geom_line(aes(y = KNN_R, color='red'), size=1,) +
labs(title='KNN: MAE od k', x='k', y='MAE') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
Porownanie_SVM_Bin <- data.frame(cbind(C = SVM_CV_bin$C[1:100], SVM_W = SVM_CV_bin$Jakosc_TEST[1:100], SVM_R = SVM_bin_R_Wynik$Accuracy[1:100]))
ggplot(Porownanie_SVM_Bin , aes(x=k)) +
geom_line(aes(y = SVM_W, color='blue'), size=1, ) +
geom_line(aes(y = SVM_R, color='red'), size=1,) +
labs(title='SVM Porownanie: Accuracy od C', x='C', y='Accuracy') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
Porownanie_SVM_Bin <- data.frame(cbind(C = SVM_CV_bin$C[1:100], SVM_W = SVM_CV_bin$Jakosc_TEST[1:100], SVM_R = SVM_bin_R_Wynik$Accuracy[1:100]))
ggplot(Porownanie_SVM_Bin , aes(x=C)) +
geom_line(aes(y = SVM_W, color='blue'), size=1, ) +
geom_line(aes(y = SVM_R, color='red'), size=1,) +
labs(title='SVM Porownanie: Accuracy od C', x='C', y='Accuracy') +
scale_color_discrete(name = "Implementacja", labels = c("Wlasna", "Biblioteka R")) +
theme(legend.position = "bottom")
print(NN_CV_bin)
print(NN_CV_multi)
print(NN_CV_reg)
ggplot(NN_bin_R_Wynik , aes(x=size)) +
geom_line(aes(y = Accuracy), size=1, color="blue") +
labs(title='NNET: Accuracy w zaleznosci od liczby neuronow - Binarny', x='h', y='Accuracy')
ggplot(NN_multi_R_Wynik , aes(x=size)) +
geom_line(aes(y = Accuracy), size=1, color="blue") +
labs(title='NNET: Accuracy w zaleznosci od liczby neuronow - Wieloklasowy', x='h', y='Accuracy')
ggplot(NN_reg_R_Wynik , aes(x=size)) +
geom_line(aes(y = MAE), size=1, color="blue") +
labs(title='NNET: MAE w zaleznosci od liczby neuronow - Regresja', x='h', y='MAE')
ggplot(Tree_bin_R_Wynik , aes(x=maxdepth)) +
geom_line(aes(y = Accuracy), size=1, color='blue') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia - Binarna', x='Max Depth', y='Accuracy')+
theme(legend.position = "bottom")
ggplot(Tree_multi_R_Wynik , aes(x=maxdepth)) +
geom_line(aes(y = Accuracy), size=1, color='blue') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia - Wieloklasowa', x='Max Depth', y='Accuracy')+
theme(legend.position = "bottom")
ggplot(Tree_reg_R_Wynik , aes(x=maxdepth)) +
geom_line(aes(y = MAE), size=1, color='blue') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia - Regresja', x='Max Depth', y='MAE')+
theme(legend.position = "bottom")
plot(Tree_bin_R$bestTune)
(Tree_bin_R$bestTune)
plot(Tree_bin_R$finalModel)
rpart.plot(Tree_bin_R$finalModel)
library(rpart.plot)
rpart.plot(Tree_bin_R$finalModel)
rpart.plot(Drzewko_bin)
rpart.plot(Tree_multi_R$finalModel)
rpart.plot(Tree_reg_R$finalModel)
tree_grid_reg = expand.grid(maxdepth=2:15)
Tree_reg_R = train(x=df_reg[,X_nazwy_reg], y=as.numeric(df_reg_norm[,Y_nazwy_reg]), tuneGrid=tree_grid_reg, method='rpart2', metric='MAE', trControl=cv_R)
Tree_reg_R_Wynik = Tree_reg_R$results
print(paste("Najlepszy Tree w R - Regresja: Max Depth = ", Tree_reg_R[["finalModel"]][["tuneValue"]][["maxdepth"]], " | MAE = " , Tree_reg_R_Wynik$MAE[Tree_reg_R_Wynik$maxdepth == Tree_reg_R[["finalModel"]][["tuneValue"]][["maxdepth"]]]))
ggplot(Tree_reg_R_Wynik , aes(x=maxdepth)) +
geom_line(aes(y = MAE), size=1, color='blue') +
labs(title='RPART: Zaleznosc pomiedzy jakoscia a glebokoscia - Regresja', x='Max Depth', y='MAE')+
theme(legend.position = "bottom")
rpart.plot(Tree_reg_R$finalModel)
rpart.plot(Tree_reg_R$finalModel)
print("Wlasna Implementacja - Drzewa Decyzyjne - Diagramy")
cat("\n")
print("Drzewa Decyzyjne - Binarny")
Drzewko_bin <- Tree(Y_nazwy_bin, X_nazwy_bin, data=df_bin, type='Gini', depth=Tree_bin_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
plot(Drzewko_bin)
print(Drzewko_bin)
Drzewko_bin <- Tree(Y_nazwy_bin, X_nazwy_bin, data=df_bin, type='Gini', depth=3, minobs=2, overfit='none', cf=0.001)
plot(Drzewko_bin)
Drzewko_bin <- Tree(Y_nazwy_bin, X_nazwy_bin, data=df_bin, type='Gini', depth=5, minobs=2, overfit='none', cf=0.001)
plot(Drzewko_bin)
print(Drzewko_bin)
Drzewko_bin <- Tree(Y_nazwy_bin, X_nazwy_bin, data=df_bin_original, type='Gini', depth=5, minobs=2, overfit='none', cf=0.001)
plot(Drzewko_bin)
Drzewko_bin <- Tree(Y_nazwy_bin, X_nazwy_bin, data=df_bin_norm, type='Gini', depth=5, minobs=2, overfit='none', cf=0.001)
plot(Drzewko_bin)
Drzewko_bin <- Tree(Y_nazwy_bin, X_nazwy_bin, data=df_bin, type='Gini', depth=Tree_bin_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=4, overfit='none', cf=0.001)
plot(Drzewko_bin)
Drzewko_multi <- Tree(Y_nazwy_multi, X_nazwy_multi, data=df_multi, type='Gini', depth=Tree_multi_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
plot(Drzewko_multi)
plot(Drzewko_bin)
plot(Drzewko_multi)
Drzewko_reg <- Tree(Y_nazwy_reg, X_nazwy_reg, data=df_reg, type='SS', depth=Tree_reg_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
plot(Drzewko_reg)
print("Neural Network - OLD - Ocena modelu na calym zbiorze: BINARNY")
X = as.matrix(df_bin_norm[,1:5])
Y = as.matrix(MinMax(df_bin_norm[,6]))
# NN_model_Bin <- trainNN( X, Y, h = c(5,5), lr = 0.01, iter = 10000, seed = 123, typ = "binarna", f_aktywacji = sigmoid, df_aktywacji = dsigmoid)
# NN_predict_Bin <- predNN( X, NN_model_Bin, typ = "binarna", f_aktywacji = sigmoid)
# print(NN_predict_Bin)
# ModelOcena((df_bin[,6]), as.numeric(NN_predict_Bin))
NN_model_Bin_old <- trainNN_old( X, Y, h = c(5,5), lr = 0.01, iter = 10000, seed = 123, typ = "binarna")
NN_predict_Bin_old <- predNN_old( X, NN_model_Bin_old, typ = "binarna")
# print(NN_predict_Bin_old)
# print("Neural Network - Ocena modelu na calym zbiorze: BINARNY")
print(ModelOcena((df_bin[,6]), as.numeric(NN_predict_Bin_old))[[3]])
print("--------------------------------------------------")
print("Neural Network - OLD - Ocena modelu na calym zbiorze: WIELOKLASOWY")
X = as.matrix(df_multi_norm[,1:4])
Y = model.matrix( ~ df_multi[,5] - 1, df_multi )
NN_model_Multi_old <- trainNN_old( X, Y, h = c(5,5), lr = 0.01, iter = 80000, seed = 123, typ = "wieloklasowa")
NN_predict_Multi_old <- predNN_old( X, NN_model_Multi_old, typ = "wieloklasowa")
klasy <- levels( df_multi[,5] )
NN_pred_Klasy <- as.numeric( klasy[apply( NN_predict_Multi_old, 1, which.max )] )
print(ModelOcena_Jakosc((df_multi[,5]), NN_pred_Klasy))
print("--------------------------------------------------")
#regresja
print("Neural Network - OLD - Ocena modelu na calym zbiorze: REGRESJA")
X = as.matrix(df_reg_norm[,1:4])
Y = as.matrix(MinMax(df_reg_norm[,5]))
Y_min = min(Y)
Y_max = max(Y)
# NN_model_Reg <- trainNN( X, as.numeric(Y), h = c(5,5), lr = 0.01, iter = 10000, seed = 123, typ = "regresja", f_aktywacji = sigmoid, df_aktywacji = dsigmoid)
# NN_predict_Reg <- predNN( X, NN_model_Reg, typ = "regresja", f_aktywacji = sigmoid)
# print(NN_predict_Reg)
# print(ModelOcena((df_reg[,5]), NN_predict_Reg))
NN_model_Reg_old <- trainNN_old( X, Y, h = c(5,5), lr = 0.01, iter = 50000, seed = 123, typ = "regresja")
NN_predict_Reg_old <- predNN_old( X, NN_model_Reg_old, typ = "regresja")
NN_predict_Reg_old_Scale <- MinMaxOdwrot(NN_predict_Reg_old, Y_min, Y_max)
print(ModelOcena((df_reg_norm[,5]), NN_predict_Reg_old_Scale))
print("--------------------------------------------------")
rm(list=ls())
library(rpart.plot)
source("funkcje.R")
#dane do klasyfikacji wieloklasowej
df_multi <- read.csv("balance.csv",header=T, sep=",")
df_multi = as.data.frame(cbind(df_multi[,2:5], Class.Name = df_multi$Class.Name))
df_multi$Class.Name <- as.factor(as.numeric(df_multi$Class.Name))
df_multi_original <- df_multi
X_nazwy_multi = colnames(df_multi)[1:4]
Y_nazwy_multi = colnames(df_multi)[5]
class(df_multi)
class(df_multi[,5])
#dane do regresji
df_reg <- read.csv("servo.csv",header=T, sep=",")
df_reg$motor <- as.numeric(df_reg$motor)
df_reg$screw <- as.numeric(df_reg$screw)
df_reg_original <- df_reg
X_nazwy_reg = colnames(df_reg)[1:4]
Y_nazwy_reg = colnames(df_reg)[5]
class(df_reg)
class(df_reg[,5])
df_bin_norm <- as.data.frame(cbind(sapply(df_bin[,1:5],MinMax), Caesarian = df_bin$Caesarian))
df_multi_norm <- as.data.frame(cbind(sapply(df_multi[,1:4],MinMax), Class.Name = df_multi$Class.Name))
df_reg_norm <- as.data.frame(cbind(sapply(df_reg[,1:4],MinMax), class = df_reg$class))
#binarna
X <- df_bin[,1:5]
#Wieloklasowa
print("Drzewa Decyzyjne - Wieloklasowy")
Drzewko_multi <- Tree(Y_nazwy_multi, X_nazwy_multi, data=df_multi, type='Gini', depth=Tree_multi_R[["finalModel"]][["tuneValue"]][["maxdepth"]], minobs=2, overfit='none', cf=0.001)
Drzewko_multi <- Tree(Y_nazwy_multi, X_nazwy_multi, data=df_multi, type='Gini', depth=6, minobs=2, overfit='none', cf=0.001)
plot(Drzewko_multi)
print(Drzewko_multi)
