# 1) Do rozwiązania mają Państwo 3 problemy:
#   a) klasyfikacja binarna,
#   b) klasyfikacja wieloklasowa,
#   c) regresja.
#   Na tę chwilę każdy z Państwa otrzymał jeden zbiór danych (albo do klasyfikacji binarnej albo wieloklasowej). 
#   Z repozytorium https://archive.ics.uci.edu/ml/index.php wybieraja Państwo, wedle upodobania, dodatkowe dwa zbiory tj. 
#   do regresji i klasyfikacji (tej której nie dotyczy otrzymany już zbiór danych). 
#   
# 2) Rozwiązują Państwo 3 powyższe problemy wykorzystując opracowane algorytmy:
#   a) Dla klasyfikacji binarnej: k-najbliższych sąsiadów, drzewa decyzyjne, sieci neuronowe.
#   b) Dla klasyfikacji wieloklasowej: k-najbliższych sąsiadów, drzewa decyzyjne, sieci neuronowe.
#   c) Dla regresji: k-najbliższych sąsiadów, drzewa decyzyjne, sieci neuronowe.
# 
# 3) Porównują Państwo wyniki otrzymane dla własnych algorymtów z wynikami otrzymanymi dla algorytmów pochodzących z innych 
#    pakietów w R, np: caret, rpart, nnet, neuralnet.
# 
# 4) Analiza powinna obejmować:
#   a) Wpływ hiper-parametrów na jakość opracowanych modeli.
#      np. liczba neuronów ukrytych, liczba najbliższych sąsiadów, głębokość drzewa itd.
#   b) Porównanie wyników najlepszych modeli, własnych jak i tych wbudowanych.
# 
# 5) Spakowany katalog z projektem powinien zawierać:
#   a) Pliki z danymi źródłowymi,
#   b) Plik funkcje.R zawierający definicję wszystkich opracowanych funkcji,
#   c) Plik Glowny.R przeprowadzający całą analizę. Uruchomienie tego pliku powinno generować różne obiekty i wykresy, które umieszczone będą w pliku z wynikami.
#     - plik dla każdego z 3 problemów: wczytuje funkcje, wczytuje dane i przekształca je, przeprowadza cross-walidację własnych oraz wbudowanych algorytmów, wybiera najlepsze wyniki.
#   d) Plik o dowolnym rozszerzeniu np. pdf, docx, pptx, zawierający opis i wyniki z przeprowadzonej analizy.
# 
# 6) Projekty proszę przesłać do 20 stycznia do godziny 23.59.



print(KNN_bin_best_W)
print(KNN_multi_best_W)
print(KNN_reg_best_W)

print(Tree_bin_best_W)
print(Tree_multi_best_W)
print(Tree_reg_best_W)

print(NN_bin_best_W)
print(NN_multi_best_W)
print(NN_reg_best_W)

R - KNN
print(paste("Najlepszy KNN w R - Binarny: k = ", KNN_bin_R$finalModel$k, " | Accuracy = " ,KNN_bin_R_Wynik$Accuracy[KNN_bin_R_Wynik$k == KNN_bin_R$finalModel$k]))
print(paste("Najlepszy KNN w R - Multi: k = ", KNN_multi_R$finalModel$k, " | Accuracy = " ,KNN_multi_R_Wynik$Accuracy[KNN_multi_R_Wynik$k == KNN_multi_R$finalModel$k]))
print(paste("Najlepszy KNN w R - Regresja: k = ", KNN_reg_R$finalModel$k, " | MAE = " ,KNN_reg_R_Wynik$MAE[KNN_reg_R_Wynik$k == KNN_reg_R$finalModel$k]))

R - Tree
print(paste("Najlepszy Tree w R - Binarny: Max Depth = ", Tree_bin_R[["finalModel"]][["tuneValue"]][["maxdepth"]], " | Accuracy = " , Tree_bin_R_Wynik$Accuracy[Tree_bin_R_Wynik$maxdepth == Tree_bin_R[["finalModel"]][["tuneValue"]][["maxdepth"]]]))
print(paste("Najlepszy Tree w R - Wieloklasowy: Max Depth = ", Tree_multi_R[["finalModel"]][["tuneValue"]][["maxdepth"]], " | Accuracy = " , Tree_multi_R_Wynik$Accuracy[Tree_multi_R_Wynik$maxdepth == Tree_multi_R[["finalModel"]][["tuneValue"]][["maxdepth"]]]))
print(paste("Najlepszy Tree w R - Regresja: Max Depth = ", Tree_reg_R[["finalModel"]][["tuneValue"]][["maxdepth"]], " | MAE = " , Tree_reg_R_Wynik$MAE[Tree_reg_R_Wynik$maxdepth == Tree_reg_R[["finalModel"]][["tuneValue"]][["maxdepth"]]]))

R - NN
print(paste("Najlepszy NN w R - Binarny: h = ", NN_bin_R[["finalModel"]][["tuneValue"]][["size"]], " | Accuracy = " , NN_bin_R_Wynik$Accuracy[NN_bin_R_Wynik$size == NN_bin_R[["finalModel"]][["tuneValue"]][["size"]]]))
print(paste("Najlepszy NN w R - Wieloklasowy: h = ", NN_multi_R[["finalModel"]][["tuneValue"]][["size"]], " | Accuracy = " , NN_multi_R_Wynik$Accuracy[NN_multi_R_Wynik$size == NN_multi_R[["finalModel"]][["tuneValue"]][["size"]]]))
print(paste0("Najlepszy NN w R - Regresja: h = ", NN_reg_R[["finalModel"]][["tuneValue"]][["size"]], " | MAE = " , NN_reg_R_Wynik$MAE[NN_reg_R_Wynik$size == NN_reg_R[["finalModel"]][["tuneValue"]][["size"]]][1]))
