{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nestle - Zadanie Rekturacyjne\n",
    "## Business Case - Data Science Hub\n",
    "### Autor: Szymon Baczyński"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wczytanie danych i przegląd\n",
    "### Pliki treningowe: X_train.csv & Y_train.csv\n",
    "### Pliki testowe: X_test.csv & Y_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import IPython.display as Disp\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych i szybki przeglad\n",
    "X_train = pd.read_csv(\"X_train.csv\", delimiter= \";\", decimal=\",\")\n",
    "X_train.info()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozmiar i nazwy kolumn\n",
    "X_train.shape\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID produktow w danych treningowych\n",
    "X_train.key.unique()\n",
    "\n",
    "# Ilosc unikalnych produktow\n",
    "X_train.key.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie zakresu dat\n",
    "X_train.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie co sie dzieje w danych - nowe produkty (w czasie) + zmienna ilosc danych dla poszczegolnych produktow\n",
    "X_train.groupby('key').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ile jest wartosci w poszczegolnych kolumnach -> nie ma problemu w 'key' i 'date'\n",
    "X_train.isnull().sum()\n",
    "# i ilosc wartosci nieliczbowych dla poszczegolnych produktow\n",
    "# pd.concat([X_train.loc[:,'key'], X_train.isnull().sum(axis=1)], axis=1).groupby('key').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzmy przy okazji dane \"target\" -> \"Y\"\n",
    "Y_train = pd.read_csv(\"Y_train.csv\", delimiter= \";\", decimal=\",\")\n",
    "Y_train.info()\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zobaczmy ile jest wartosci null czy NaN\n",
    "Y_train.isnull().sum()\n",
    "Y_train[Y_train.isnull().any(axis=1)]\n",
    "Y_train[Y_train.isnull().any(axis=1)].groupby('key').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dane \"Y\" - produkty tez maja rozna ilosc dat\n",
    "Y_train.groupby('key').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzmy czy ilosc dat dla X i Y w zbiorze treningowym sie zgadzaja\n",
    "all(X_train.groupby('key').count().date == Y_train.groupby('key').count().date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zduplikowane wiersze \"key\" i \"date\"?\n",
    "X_train.duplicated(subset=['key','date']).any()\n",
    "Y_train.duplicated(subset=['key','date']).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling - zróbmy z tego dane, które da się czytać"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://miro.medium.com/max/400/0*TXDoF8j-D3LuGbHP.jpg'\n",
    "Disp.Image(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naprawmy kolumne z datami\n",
    "X_train['date'] = pd.to_datetime(X_train['date'], format='%d%b%Y')\n",
    "X_train.info()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:,2:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some variables 'x' for random keys to show missing data\n",
    "rand_keys = random.choices(X_train['key'].unique(), k=5)\n",
    "rand_keys\n",
    "\n",
    "for keys in rand_keys:\n",
    "    pyplot.plot(X_train.loc[X_train['key'] == keys].date, X_train.loc[X_train['key'] == keys].iloc[:,3:10]);\n",
    "    pyplot.legend(X_train.iloc[:,3:10].columns);\n",
    "    pyplot.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notatki:\n",
    "- Widać ubytki w danych, często dość kluczowe - można by zastosować średnią kroczącą, w celu uzupełnienia \n",
    "- Niestety takie uzupełnianie może nie być prawdziwe - warto zapytać klienta czy nie ma tych danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Czyszczenie wartosci NaN / NULL\n",
    "\n",
    "# X_train_copy.fillna(0.0)\n",
    "# X_train_copy = X_train_copy.fillna(X_train_copy.rolling(20,min_periods=1).mean())\n",
    "\n",
    "col_names = X_train.iloc[:,2:].columns\n",
    "X_train_copy[col_names] = X_train_copy.groupby('key')[col_names]\\\n",
    "    .transform(lambda x: x.fillna(x.rolling(3,min_periods=1).mean()))\n",
    "\n",
    "X_train_copy.fillna(0.0, inplace=True)\n",
    "# Znalezc jak sie robi fillna z 0 na poczatku a pozniej innymi wartosciami\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train['key'] == 683].isnull().sum().sum()\n",
    "X_train_copy.loc[X_train_copy['key'] == 683].isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uzupelnienie wartosci \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korelacja\n",
    "# https://medium.com/@sebastiannorena/finding-correlation-between-many-variables-multidimensional-dataset-with-python-5deb3f39ffb3\n",
    "# https://machinelearningmastery.com/how-to-use-correlation-to-understand-the-relationship-between-variables/\n",
    "# https://stackoverflow.com/questions/42128462/in-python-how-to-do-correlation-between-multiple-columns-more-than-2-variables\n",
    "# https://realpython.com/numpy-scipy-pandas-correlation-python/\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c47ed5ea5715a4a51b054519cba8338cf6f0a3376d3bdd436322f7488713b6fe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
