{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nestle - Zadanie Rekturacyjne\n",
    "## Business Case - Data Science Hub\n",
    "### Autor: Szymon Baczyński"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wczytanie danych i przegląd\n",
    "### Pliki treningowe: X_train.csv & Y_train.csv\n",
    "### Pliki testowe: X_test.csv & Y_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datatable as dt      # For bigger files - data.table - faster (or use dplyr)\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "import IPython.display as Disp\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych i szybki przeglad\n",
    "X_train = pd.read_csv(\"X_train.csv\", delimiter= \";\", decimal=\",\")\n",
    "X_train.info()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozmiar i nazwy kolumn\n",
    "X_train.shape\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID produktow w danych treningowych\n",
    "X_train.key.unique()\n",
    "\n",
    "# Ilosc unikalnych produktow\n",
    "X_train.key.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie zakresu dat\n",
    "X_train.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie co sie dzieje w danych - nowe produkty (w czasie) + zmienna ilosc danych dla poszczegolnych produktow\n",
    "X_train.groupby('key').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ile jest wartosci w poszczegolnych kolumnach -> nie ma problemu w 'key' i 'date'\n",
    "X_train.isnull().sum()\n",
    "# i ilosc wartosci nieliczbowych dla poszczegolnych produktow\n",
    "# pd.concat([X_train.loc[:,'key'], X_train.isnull().sum(axis=1)], axis=1).groupby('key').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzmy przy okazji dane \"target\" -> \"Y\"\n",
    "Y_train = pd.read_csv(\"Y_train.csv\", delimiter= \";\", decimal=\",\")\n",
    "Y_train.info()\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zobaczmy ile jest wartosci null czy NaN\n",
    "Y_train.isnull().sum()\n",
    "Y_train[Y_train.isnull().any(axis=1)]\n",
    "Y_train[Y_train.isnull().any(axis=1)].groupby('key').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dane \"Y\" - produkty tez maja rozna ilosc dat\n",
    "Y_train.groupby('key').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzmy czy ilosc dat dla X i Y w zbiorze treningowym sie zgadzaja\n",
    "all(X_train.groupby('key').count().date == Y_train.groupby('key').count().date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zduplikowane wiersze \"key\" i \"date\" ?\n",
    "X_train.duplicated(subset=['key','date']).any()\n",
    "Y_train.duplicated(subset=['key','date']).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling - zróbmy z tego dane, które da się czytać"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://miro.medium.com/max/400/0*TXDoF8j-D3LuGbHP.jpg'\n",
    "Disp.Image(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naprawmy kolumne z datami\n",
    "X_train['date'] = pd.to_datetime(X_train['date'], format='%d%b%Y')\n",
    "X_train.info()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kopia X_train aby uzupelnic wartosci NaN\n",
    "X_train_copy = X_train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uzupelnianie wartosci NaN\n",
    "\n",
    "col_names = X_train.iloc[:,2:].columns\n",
    "X_train_copy[col_names] = X_train_copy.groupby('key')[col_names].transform(lambda x: x.fillna(x.rolling(3,min_periods=1).mean()))\n",
    "\n",
    "X_train_copy.fillna(0.0, inplace=True)\n",
    "\n",
    "### Znalezc jak sie robi fillna z 0 na poczatku a pozniej innymi wartosciami\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poprawiona data w \"Y\"\n",
    "Y_train['date'] = pd.to_datetime(Y_train['date'], format='%d%b%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_copy = Y_train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uzupelnienie wartosci \"Y\"\n",
    "Y_train_copy['y'] = Y_train_copy.groupby('key')['y'].transform(lambda x: x.fillna(x.rolling(3,min_periods=1).mean()))\n",
    "\n",
    "Y_train_copy.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_copy\n",
    "Y_train_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notatki:\n",
    "- Widać ubytki w danych, często dość kluczowe - można by zastosować średnią kroczącą, w celu uzupełnienia \n",
    "- Niestety takie uzupełnianie może nie być prawdziwe - warto zapytać klienta czy nie ma tych danych\n",
    "- W przypadku gdy brak danych, można uzupełnić je wartościami średnimi z małym okienkiem (pozostałe wartości uzupełnione 0.0)\n",
    "- W dalszej części zostanie zrobiona eksploracja obu zbiorów danych by sprawdzić jak uzupełnione wartości wpływają na zbiór"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis - sprawdźmy dane pod kątem statystyki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy.info()\n",
    "X_train_copy.head()\n",
    "\n",
    "# ID produktow w danych treningowych\n",
    "X_train_copy.key.unique()\n",
    "\n",
    "# Ilosc unikalnych produktow\n",
    "X_train_copy.key.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wglad w dane \"Y\"\n",
    "Y_train.info()\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for random product (key)\n",
    "plt.plot(Y_train[Y_train['key'] == 72159].date, Y_train[Y_train['key'] == 72159].y)\n",
    "plt.plot(Y_train[Y_train['key'] == 9902].date, Y_train[Y_train['key'] == 9902].y)\n",
    "plt.plot(Y_train[Y_train['key'] == 99444].date, Y_train[Y_train['key'] == 99444].y)\n",
    "plt.legend(['72159','9902','99444'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Czy w \"Y\" sa outliers\n",
    "sns.boxplot(x=Y_train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(Y_train_copy[Y_train_copy['key'] == 72159].y);\n",
    "plot_pacf(Y_train_copy[Y_train_copy['key'] == 72159].y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(Y_train_copy[Y_train_copy['key'] == 9902].y);\n",
    "plot_pacf(Y_train_copy[Y_train_copy['key'] == 9902].y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(Y_train_copy[Y_train_copy['key'] == 99444].y);\n",
    "plot_pacf(Y_train_copy[Y_train_copy['key'] == 99444].y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roznica miedzy zbiorem z NaN i z uzupelnionymi wartosciami\n",
    "X_train.loc[X_train['key'] == 683].isnull().sum().sum()\n",
    "X_train_copy.loc[X_train_copy['key'] == 683].isnull().sum().sum()\n",
    "X_train.isnull().sum().sum()\n",
    "X_train_copy.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:,2:].describe()\n",
    "X_train_copy.iloc[:,2:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some variables 'x' for random keys to show missing data\n",
    "rand_keys = random.choices(X_train['key'].unique(), k=5)\n",
    "rand_keys\n",
    "\n",
    "for keys in rand_keys:\n",
    "    plt.plot(X_train.loc[X_train['key'] == keys].date, X_train.loc[X_train['key'] == keys].iloc[:,3:10]);\n",
    "    plt.legend(X_train.iloc[:,3:10].columns);\n",
    "    plt.show();\n",
    "    \n",
    "    plt.plot(X_train_copy.loc[X_train_copy['key'] == keys].date, X_train_copy.loc[X_train_copy['key'] == keys].iloc[:,3:10]);\n",
    "    plt.legend(X_train_copy.iloc[:,3:10].columns);\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Y_train_with_NaN = X_train.copy(deep=True)\n",
    "X_Y_train_with_NaN.insert(2,'y',Y_train.y)\n",
    "X_Y_train_with_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_Y_train_without_NaN = pd.concat([X_train_copy, Y_train_copy.y], axis=1)\n",
    "X_Y_train_without_NaN = X_train_copy.copy(deep=True)\n",
    "X_Y_train_without_NaN.insert(2,'y',Y_train_copy.y)\n",
    "X_Y_train_without_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korelacja z NaN\n",
    "\n",
    "Train_corr_NaN = X_Y_train_with_NaN.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(Train_corr_NaN, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(X_Y_train_with_NaN.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(X_Y_train_with_NaN.columns)\n",
    "ax.set_yticklabels(X_Y_train_with_NaN.columns)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie korelacji 'y' z 'x' dla danych z NaN\n",
    "corr_NaN = X_train.corrwith(Y_train['y'])\n",
    "corr_NaN\n",
    "plt.plot(corr_NaN);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korelacja dla danych bez NaN\n",
    "\n",
    "Train_corr = X_Y_train_without_NaN.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(Train_corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(X_Y_train_without_NaN.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(X_Y_train_without_NaN.columns)\n",
    "ax.set_yticklabels(X_Y_train_without_NaN.columns)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korelacja 'y' z 'x' dla danych bez NaN - tracimy korelacje danych przez uzupelnienie wartosci NaN\n",
    "corr_without_NaN = X_train_copy.corrwith(Y_train_copy['y'])\n",
    "plt.plot(corr_without_NaN);\n",
    "corr_without_NaN[corr_without_NaN > 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_tmp_max = list()\n",
    "\n",
    "for k in range(0,13):\n",
    "    tmp = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "    corr_tmp = tmp.iloc[:,3:].shift(k, fill_value=0.0).corrwith(tmp['y'])\n",
    "    plt.plot(corr_tmp)\n",
    "    corr_tmp_max.append((corr_tmp[corr_tmp > 0.5]))\n",
    "\n",
    "plt.legend(range(0,13))\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(corr_tmp_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "corr_tmp = tmp.iloc[:,3:].corrwith(tmp['y'])\n",
    "plt.plot(corr_tmp);\n",
    "corr_tmp[corr_tmp > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korelacja wzgledem przesunietych 'X'\n",
    "\n",
    "tmp_1 = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "corr_tmp_1 = tmp_1.iloc[:,3:].shift(1, fill_value=0.0).corrwith(tmp_1['y'])\n",
    "plt.plot(corr_tmp_1);\n",
    "corr_tmp_1[corr_tmp_1 > 0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_2 = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "corr_tmp_2 = tmp_2.iloc[:,3:].shift(2, fill_value=0.0).corrwith(tmp_2['y'])\n",
    "plt.plot(corr_tmp_2);\n",
    "corr_tmp_2[corr_tmp_2 > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_3 = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "corr_tmp_3 = tmp_3.iloc[:,3:].shift(3, fill_value=0.0).corrwith(tmp_3['y'])\n",
    "plt.plot(corr_tmp_3);\n",
    "corr_tmp_3[corr_tmp_3 > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_4 = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "corr_tmp_4 = tmp_4.iloc[:,3:].shift(4, fill_value=0.0).corrwith(tmp_4['y'])\n",
    "plt.plot(corr_tmp_4);\n",
    "corr_tmp_4[corr_tmp_4 > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_5 = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "corr_tmp_5 = tmp_5.iloc[:,3:].shift(5, fill_value=0.0).corrwith(tmp_5['y'])\n",
    "plt.plot(corr_tmp_5);\n",
    "corr_tmp_5[corr_tmp_5 > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_6 = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "corr_tmp_6 = tmp_6.iloc[:,3:].shift(6, fill_value=0.0).corrwith(tmp_6['y'])\n",
    "plt.plot(corr_tmp_6);\n",
    "corr_tmp_6[corr_tmp_6 > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_7 = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "corr_tmp_7 = tmp_7.iloc[:,3:].shift(7, fill_value=0.0).corrwith(tmp_7['y'])\n",
    "plt.plot(corr_tmp_7);\n",
    "corr_tmp_7[corr_tmp_7 > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_8 = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == 9902]\n",
    "corr_tmp_8 = tmp_8.iloc[:,3:].shift(8, fill_value=0.0).corrwith(tmp_8['y'])\n",
    "plt.plot(corr_tmp_8);\n",
    "corr_tmp_8[corr_tmp_8 > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best correlation \n",
    "\n",
    "shift_start = 1\n",
    "shift_lookin = 9\n",
    "\n",
    "key_ID = list(np.repeat(X_train_copy['key'].unique(), shift_lookin-shift_start))\n",
    "key_shift = list(itertools.chain.from_iterable(list(itertools.repeat(list(range(shift_start,shift_lookin)), X_train_copy.key.nunique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which 'x' is important (corr > 0.5) for every 'key'\n",
    "\n",
    "corr_list = list()\n",
    "\n",
    "for key in X_train_copy['key'].unique():\n",
    "    for m_shift in range(shift_start,shift_lookin):\n",
    "        tmp = X_Y_train_without_NaN[X_Y_train_without_NaN['key'] == key]\n",
    "        corr_tmp = tmp.iloc[:,3:].shift(m_shift, fill_value=0.0).corrwith(tmp['y'])\n",
    "        corr_list.append(list(corr_tmp))\n",
    "\n",
    "corr_max = pd.DataFrame(corr_list, columns=X_train_copy.columns[2:])\n",
    "corr_max.insert(0,'key', key_ID)\n",
    "corr_max.insert(1,'shift', key_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_max.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korelacja Dodatnia\n",
    "corr_max_sum = (corr_max.iloc[:,2:] > 0.5).sum()\n",
    "plt.plot(corr_max_sum);\n",
    "\n",
    "corr_max_sum[corr_max_sum > 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ujemna Korelacja \n",
    "\n",
    "corr_min_sum = (corr_max.iloc[:,2:] < -0.5).sum()\n",
    "plt.plot(corr_min_sum);\n",
    "\n",
    "corr_min_sum[corr_min_sum > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which \"shift\" is the best for each 'x' - FOR ALL MODEL\n",
    "\n",
    "columns_select = list(['shift'])\n",
    "columns_select.extend(list(corr_max_sum[corr_max_sum > 5].index))\n",
    "\n",
    "best_corr_columns = corr_max.loc[:,columns_select]\n",
    "best_corr_columns.groupby('shift').max()\n",
    "\n",
    "# plt.plot(best_corr_columns.groupby('shift').max());\n",
    "\n",
    "df = best_corr_columns.groupby('shift').max()\n",
    "fig = px.line(df, x=df.index, y=df.columns)\n",
    "fig.show()\n",
    "\n",
    "# plt.legend(list(corr_max_sum[corr_max_sum > 5].index), loc=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which \"shift\" is the best for each 'x' - FOR MODEL PER KEY (PRODUCT)\n",
    "\n",
    "columns_select = list(['shift'])\n",
    "columns_select.extend(list(corr_max_sum[corr_max_sum > 5].index))\n",
    "\n",
    "best_corr_columns = corr_max.loc[:,columns_select]\n",
    "best_corr_columns.groupby('shift').max()\n",
    "\n",
    "plt.plot(best_corr_columns.groupby('shift').max());\n",
    "plt.legend(list(corr_max_sum[corr_max_sum > 5].index), loc=5);"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c47ed5ea5715a4a51b054519cba8338cf6f0a3376d3bdd436322f7488713b6fe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
