{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testowy_CNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiAyrbTvOdY0"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJkkAbW9OjEO"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHCCyNqfOmj0"
      },
      "source": [
        "!kaggle datasets download -d shayanfazeli/heartbeat --unzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5xVx1jMOt-U"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.engine.input_layer import Input\n",
        "from tensorflow.python.ops.gen_array_ops import shape\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, concatenate\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJStaL6JOxiq"
      },
      "source": [
        "# Dane Treningowe\n",
        "train_raw = pd.read_csv(\"mitbih_train.csv\", header=None)\n",
        "print(train_raw.head())\n",
        "print(train_raw.describe())\n",
        "\n",
        "print(\"Rozklad klas w danych treningowych\")\n",
        "train_raw[187] = train_raw[187].astype(int)\n",
        "train_class_spread = train_raw.pivot_table(index = [187], aggfunc ='size')\n",
        "print(train_class_spread)\n",
        "sns.catplot(x = 187, kind = 'count', data = train_raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO1eGpAGOz8c"
      },
      "source": [
        "# Dane Testowe\n",
        "test_raw = pd.read_csv(\"mitbih_test.csv\", header=None)\n",
        "print(test_raw.head())\n",
        "print(test_raw.describe())\n",
        "\n",
        "print(\"Rozklad klas w danych testowych\")\n",
        "test_raw[187] = test_raw[187].astype(int)\n",
        "test_class_spread = test_raw.pivot_table(index = [187], aggfunc ='size')\n",
        "print(test_class_spread)\n",
        "sns.catplot(x = 187, kind = 'count', data = test_raw)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H-VksP-O2c-"
      },
      "source": [
        "# Ze wzgledu na rozklad klas w danych treningowych, nalezy zbalansowac ilosc klas:\n",
        "# \n",
        "# N: Non Ectopic beats (Normal beats)\n",
        "# S: Supraventrical ectopic beats\n",
        "# V: Ventricular ectopic beats\n",
        "# F: Fusion beats\n",
        "# Q: Unknown beats\n",
        "#\n",
        "# Klasa: 0 = 72471\n",
        "# Klasa: 1 =  2223\n",
        "# Klasa: 2 =  5788\n",
        "# Klasa: 3 =   641\n",
        "# Klasa: 4 =  6431\n",
        "#\n",
        "# - metoda upsamplingu i downsamplingu - ujednolicenie danych na poziomie ...\n",
        "\n",
        "# Poki uzyte zostana wszystkie dane!!! "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMSovU0LO3On"
      },
      "source": [
        "Y_train = to_categorical(train_raw[187].values)\n",
        "X_train = np.array(train_raw.iloc[:,:-1].values)\n",
        "# X = np.array(train_raw.iloc[:,-1:].values)[..., np.newaxis]\n",
        "\n",
        "Y_test = to_categorical(test_raw[187].values)\n",
        "X_test = np.array(test_raw.iloc[:,:-1].values)\n",
        "# X_test = np.array(train_raw.iloc[:,-1:].values)[..., np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcX-8Op8OHP7"
      },
      "source": [
        "print(X_train)\n",
        "print(Y_train)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7fGUb9oO45B"
      },
      "source": [
        "X_train = X_train.reshape(len(X_train),X_train.shape[1],1)\n",
        "X_test = X_test.reshape(len(X_test),X_test.shape[1],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7QlewKdO61n"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhGZa81QTK50"
      },
      "source": [
        "def conv_unit(unit, input_layer):\n",
        "    s = '_' + str(unit)\n",
        "    layer = keras.layers.Conv1D(name='Conv1' + s, filters=32, kernel_size=5, strides=1, padding='same', activation='relu')(input_layer)\n",
        "    layer = keras.layers.Conv1D(name='Conv2' + s, filters=32, kernel_size=5, strides=1, padding='same', activation=None)(layer )\n",
        "    layer = keras.layers.Add(name='ResidualSum' + s)([layer, input_layer])\n",
        "    layer = keras.layers.Activation(\"relu\", name='Act_relu' + s)(layer)\n",
        "    layer = keras.layers.MaxPooling1D(name='MaxPool' + s, pool_size=5, strides=2)(layer)\n",
        "    return layer\n",
        "\n",
        "def get_uncompiled_model():\n",
        "\n",
        "    inputs = keras.layers.Input(shape=(187,1), name=\"Inputo\")\n",
        "    current_layer = keras.layers.Conv1D(name='Conv1D_1', filters=32, kernel_size=5, strides=1, padding='same', input_shape=(187,1))(inputs)\n",
        "\n",
        "    for i in range(5):\n",
        "        current_layer = conv_unit(i + 1, current_layer)\n",
        "\n",
        "    current_layer = keras.layers.Flatten()(current_layer)\n",
        "    \n",
        "    current_layer = keras.layers.Dense(32, name='FC1', activation='relu')(current_layer)\n",
        "    current_layer = keras.layers.Dense(32, name='FC2')(current_layer)\n",
        "    output_layer = keras.layers.Dense(5, name='Output', activation='softmax')(current_layer)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_compiled_model():\n",
        "    model = get_uncompiled_model()\n",
        "    model.compile(\n",
        "        optimizer='adam', \n",
        "        loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0chFfraLUU7E"
      },
      "source": [
        "model = get_compiled_model()\n",
        "file_path = \"baseline_cnn_mitbih.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=10, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHwNgkvgkvK6"
      },
      "source": [
        "for layer in model.layers:\n",
        "    print(str(layer.name) + \" : \" + str(layer.input_shape) + \" >> X >> \" + str(layer.output_shape))\n",
        "    # print(layer.output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv0XoOnSVslj"
      },
      "source": [
        "history = model.fit(X_train, Y_train, epochs = 10, callbacks=callbacks_list, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUjSCi72lXmL"
      },
      "source": [
        "pd.DataFrame(history.history)\n",
        "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\n",
        "pd.DataFrame(history.history)[['loss', 'val_loss']].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-34CYtvmlIQ"
      },
      "source": [
        "# Predicted o/p will be in probability distribution \n",
        "predict = model.predict(X_test)\n",
        "\n",
        "# distributional probability to integers\n",
        "yhat = np.argmax(predict, axis = 1)\n",
        "\n",
        "confusion_matrix(np.argmax(Y_test, axis = 1), yhat)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(confusion_matrix(np.argmax(Y_test, axis =1), yhat), annot = True, fmt = '0.0f', cmap= 'RdPu')\n",
        "\n",
        "print(classification_report(np.argmax(Y_test, axis=1), yhat))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}